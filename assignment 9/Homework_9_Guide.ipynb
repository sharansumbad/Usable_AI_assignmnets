{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 9 Guide\n",
    "In this guide, we will apply NLP concepts from lecture and use TF-IDF Vectorization. We will need to use the sentiment dataset linked to from the canvas assignment page. Make sure to have this downloaded for using this guide. As always, we'll first need a few libraries for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to convert the text files over to a pandas dataframe. We'll need to use the `open()` function to read in the text file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '' # Your Code Here\n",
    "f = open(filepath, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll iterate through all of the lines in the text file, and pull the data into the dataframe using the `append()` function for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "for line in f:\n",
    "    \n",
    "    review = line[:len(line) - 2]\n",
    "    sentiment = line[len(line)-2]\n",
    "    row = [review, sentiment]\n",
    "    data._(row) # Your Code Here\n",
    "    \n",
    "df = pd.DataFrame(data, columns = ['reviews', 'sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we need to clean up the dataframe by removing non words like stop-test, and punctuation. Fill in the code for the `remove_punctuation()` and `remove_stopwords()` functions as described in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Your Code Here\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Your Code Here\n",
    "    \n",
    "df['reviews'] = df['reviews'].apply(remove_punctuation).apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can call the `TfidfVectorizer()` function, passing it 'english' as a parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = _('') # Your Code Here\n",
    "tfidf_vectorizer.fit(df['reviews'])\n",
    "dictionary = tfidf_vectorizer.vocabulary_.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to unpack this dictionary and sort the values. In the cell below, grab the words using the `keys()` function, and the counts using `values()`. Then, sort the values using `sort_values()`, with the `ascending` parameter set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "count = []\n",
    "\n",
    "for key, value in dictionary:\n",
    "    # Your Code Here\n",
    "    \n",
    "vocab_bef_stem = pd.Series(count, index=vocab)\n",
    "vocab_bef_stem = vocab_bef_stem._(ascending=_) # Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, let's see what our top 10 words are. Using the `head()` function, pull the top 10 values then display by setting the `kind` to 'barh'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_vocab = # Your Code Here\n",
    "top_vocab.plot(kind='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Please sumbit this workbook completed with your top_vocab plot visible above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
