{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "listed-sector",
   "metadata": {},
   "source": [
    "### Homework 8 Guide\n",
    "<br>\n",
    "In this guide, we will be conducting model evaluation through feature selection on the classification techniques to find the best model that our soccer database. Make sure to have the soccer database downloaded for working with this guide. As always, we'll need some libaries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "closed-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-ocean",
   "metadata": {},
   "source": [
    "We'll need to connect to the soccer database to start, let's do that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "variable-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "\n",
    "# importing soccer data\n",
    "conn = sqlite3.connect(\"database.sqlite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-orlando",
   "metadata": {},
   "source": [
    "Let's grab the `strength`, `stamina`, and `jumping` columns from the `Player_Attributes` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driven-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Player_Attributes table to dataframe\n",
    "\n",
    "player_attr_df = pd.read_sql(\"SELECT strength, stamina, jumping FROM Player_Attributes\", conn)\n",
    "\n",
    "# Filling with 11 for all null values\n",
    "player_attr_df.fillna(11, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-insertion",
   "metadata": {},
   "source": [
    "Now let's grab our `x` and `y`. Use strength and stamina for `x`, and jumping for `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coupled-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = player_attr_df[['strength', 'stamina']].values\n",
    "y = player_attr_df[['jumping']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-brooks",
   "metadata": {},
   "source": [
    "To get started, we need to split the data. Using `train_test_split()`, split the sample by 30%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "toxic-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-dairy",
   "metadata": {},
   "source": [
    "Now we can get our DecisionTreeClassifier up. Run the cell below to set it up. You may get a warning regarding the split. This is okay for completing this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moral-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree best grid score: 0.1615495474917537\n",
      "Decision Tree grid test score: 0.1622821321158097\n",
      "Decision Tree best params: {'criterion': 'entropy', 'max_depth': 30, 'random_state': 4, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "desicion_tree_params_grid = {'criterion':['gini','entropy'], 'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50], 'splitter':[\"best\", \"random\"], 'random_state':[0,1,2,4,6,8,10,12,14,16,20,40,42]}\n",
    "grid_search_decision_tree_classifier = GridSearchCV(DecisionTreeClassifier(), desicion_tree_params_grid, cv=10)\n",
    "grid_search_decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Decision Tree best grid score: \" + str(grid_search_decision_tree_classifier.best_score_))\n",
    "print(\"Decision Tree grid test score: \" + str(grid_search_decision_tree_classifier.score(X_test, y_test)))\n",
    "\n",
    "decision_tree_best_params = grid_search_decision_tree_classifier.best_params_\n",
    "print(\"Decision Tree best params: \" + str(decision_tree_best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-norwegian",
   "metadata": {},
   "source": [
    "Now we can run `predict()` on our `grid_search_decision_tree_classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stock-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search_decision_tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-inquiry",
   "metadata": {},
   "source": [
    "Let's look at the resulting report. Call `classification_report()` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "heated-acoustic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification report with whole data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        11.0       0.82      0.32      0.47       757\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         6\n",
      "        22.0       0.00      0.00      0.00         6\n",
      "        24.0       0.00      0.00      0.00         3\n",
      "        25.0       0.30      0.25      0.27        12\n",
      "        26.0       0.00      0.00      0.00         5\n",
      "        27.0       0.40      0.30      0.34        20\n",
      "        28.0       0.40      0.43      0.41        14\n",
      "        29.0       0.16      0.23      0.19        13\n",
      "        30.0       0.16      0.07      0.10        54\n",
      "        31.0       0.37      0.12      0.18        59\n",
      "        32.0       0.19      0.16      0.17       127\n",
      "        33.0       0.22      0.30      0.25       172\n",
      "        34.0       0.14      0.16      0.15       277\n",
      "        35.0       0.75      0.16      0.27        37\n",
      "        36.0       0.27      0.18      0.21        45\n",
      "        37.0       0.41      0.24      0.31        45\n",
      "        38.0       0.27      0.18      0.22        92\n",
      "        39.0       0.26      0.14      0.18        73\n",
      "        40.0       0.34      0.20      0.25        85\n",
      "        41.0       0.33      0.24      0.28       121\n",
      "        42.0       0.18      0.11      0.13       207\n",
      "        43.0       0.23      0.15      0.18       177\n",
      "        44.0       0.18      0.10      0.13       169\n",
      "        45.0       0.22      0.12      0.16       192\n",
      "        46.0       0.23      0.27      0.25       238\n",
      "        47.0       0.18      0.19      0.18       301\n",
      "        48.0       0.28      0.18      0.22       463\n",
      "        49.0       0.22      0.21      0.21       381\n",
      "        50.0       0.20      0.14      0.17       469\n",
      "        51.0       0.19      0.21      0.20       515\n",
      "        52.0       0.21      0.20      0.20       658\n",
      "        53.0       0.21      0.15      0.17       704\n",
      "        54.0       0.26      0.17      0.21       973\n",
      "        55.0       0.22      0.19      0.21      1051\n",
      "        56.0       0.25      0.18      0.21      1029\n",
      "        57.0       0.22      0.21      0.22      1098\n",
      "        58.0       0.17      0.20      0.18      1292\n",
      "        59.0       0.18      0.18      0.18      1184\n",
      "        60.0       0.15      0.17      0.16      1442\n",
      "        61.0       0.16      0.19      0.17      1456\n",
      "        62.0       0.17      0.17      0.17      1903\n",
      "        63.0       0.15      0.15      0.15      1616\n",
      "        64.0       0.12      0.15      0.14      2000\n",
      "        65.0       0.15      0.17      0.16      1793\n",
      "        66.0       0.17      0.18      0.17      1916\n",
      "        67.0       0.14      0.16      0.15      1904\n",
      "        68.0       0.13      0.14      0.14      1927\n",
      "        69.0       0.14      0.15      0.15      1797\n",
      "        70.0       0.14      0.24      0.17      2516\n",
      "        71.0       0.14      0.21      0.17      2270\n",
      "        72.0       0.14      0.20      0.17      2593\n",
      "        73.0       0.12      0.19      0.15      1965\n",
      "        74.0       0.13      0.17      0.15      1950\n",
      "        75.0       0.14      0.15      0.14      1745\n",
      "        76.0       0.16      0.08      0.11      1454\n",
      "        77.0       0.15      0.13      0.14      1113\n",
      "        78.0       0.16      0.10      0.13      1180\n",
      "        79.0       0.22      0.09      0.13       883\n",
      "        80.0       0.16      0.10      0.12      1306\n",
      "        81.0       0.17      0.09      0.11      1084\n",
      "        82.0       0.16      0.04      0.07       872\n",
      "        83.0       0.25      0.08      0.12       655\n",
      "        84.0       0.18      0.09      0.12       563\n",
      "        85.0       0.17      0.08      0.11       440\n",
      "        86.0       0.19      0.08      0.11       362\n",
      "        87.0       0.12      0.07      0.09       220\n",
      "        88.0       0.20      0.05      0.08       195\n",
      "        89.0       0.32      0.05      0.09       117\n",
      "        90.0       0.29      0.09      0.13       322\n",
      "        91.0       0.26      0.11      0.15       235\n",
      "        92.0       0.37      0.14      0.20       137\n",
      "        93.0       0.50      0.02      0.05        81\n",
      "        94.0       0.10      0.03      0.04        39\n",
      "        95.0       0.00      0.00      0.00        12\n",
      "        96.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.16     55194\n",
      "   macro avg       0.21      0.14      0.16     55194\n",
      "weighted avg       0.18      0.16      0.16     55194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "grid_search_decision_tree_classification_report = classification_report(y_test, y_pred)\n",
    "print(\"Decision Tree Classification report with whole data\")\n",
    "print(grid_search_decision_tree_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-blend",
   "metadata": {},
   "source": [
    "We'll need to grab the features to use now, using the `SelectFromModel()` function. Then, let's run `fit()` on `select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hollywood-rachel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/feature_selection/_from_model.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median') # Your Code Here\n",
    "\n",
    "\n",
    "# Selecting features using RandomForestClassifier\n",
    "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold='median')\n",
    "select.fit(X_train, y_train)\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-remark",
   "metadata": {},
   "source": [
    "Now let's apply those best params froem the grid search. Assign the respective fields from `decision_tree_best_params` for your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "imperial-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying DecisionTreeClassifier using the best params from the grid search and with selected data\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion = decision_tree_best_params['criterion'],\\\n",
    "    max_depth = decision_tree_best_params['max_depth'],\\\n",
    "    random_state = decision_tree_best_params['random_state'],\\\n",
    "    splitter = decision_tree_best_params['splitter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-advertising",
   "metadata": {},
   "source": [
    "We need to run the `fit()` function using `X_train_selected` and `y_train` as parameters. Then, run `predict()` using `X_test_selected`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "understanding-methodology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree_classifier.fit(X_train_selected, y_train)\n",
    "y_pred = decision_tree_classifier.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-stuff",
   "metadata": {},
   "source": [
    "Lastly, rerun the `classification_report()` and print out what your results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "printable-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "systematic-brush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification report with selected data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        11.0       1.00      0.31      0.47       757\n",
      "        14.0       0.00      0.00      0.00         1\n",
      "        20.0       0.00      0.00      0.00         1\n",
      "        21.0       0.00      0.00      0.00         6\n",
      "        22.0       0.00      0.00      0.00         6\n",
      "        24.0       0.00      0.00      0.00         3\n",
      "        25.0       0.00      0.00      0.00        12\n",
      "        26.0       0.00      0.00      0.00         5\n",
      "        27.0       0.00      0.00      0.00        20\n",
      "        28.0       0.00      0.00      0.00        14\n",
      "        29.0       0.00      0.00      0.00        13\n",
      "        30.0       0.00      0.00      0.00        54\n",
      "        31.0       0.00      0.00      0.00        59\n",
      "        32.0       0.00      0.00      0.00       127\n",
      "        33.0       0.00      0.00      0.00       172\n",
      "        34.0       0.00      0.00      0.00       277\n",
      "        35.0       0.00      0.00      0.00        37\n",
      "        36.0       0.00      0.00      0.00        45\n",
      "        37.0       0.00      0.00      0.00        45\n",
      "        38.0       0.11      0.01      0.02        92\n",
      "        39.0       0.00      0.00      0.00        73\n",
      "        40.0       0.00      0.00      0.00        85\n",
      "        41.0       0.00      0.00      0.00       121\n",
      "        42.0       0.00      0.00      0.00       207\n",
      "        43.0       0.00      0.00      0.00       177\n",
      "        44.0       0.00      0.00      0.00       169\n",
      "        45.0       0.00      0.00      0.00       192\n",
      "        46.0       0.10      0.02      0.03       238\n",
      "        47.0       0.00      0.00      0.00       301\n",
      "        48.0       0.00      0.00      0.00       463\n",
      "        49.0       0.00      0.00      0.00       381\n",
      "        50.0       0.00      0.00      0.00       469\n",
      "        51.0       0.50      0.01      0.03       515\n",
      "        52.0       0.07      0.03      0.04       658\n",
      "        53.0       0.00      0.00      0.00       704\n",
      "        54.0       0.07      0.02      0.03       973\n",
      "        55.0       0.10      0.04      0.05      1051\n",
      "        56.0       0.00      0.00      0.00      1029\n",
      "        57.0       0.11      0.05      0.07      1098\n",
      "        58.0       0.04      0.03      0.03      1292\n",
      "        59.0       0.00      0.00      0.00      1184\n",
      "        60.0       0.03      0.03      0.03      1442\n",
      "        61.0       0.00      0.00      0.00      1456\n",
      "        62.0       0.05      0.12      0.08      1903\n",
      "        63.0       0.00      0.00      0.00      1616\n",
      "        64.0       0.04      0.07      0.05      2000\n",
      "        65.0       0.06      0.05      0.05      1793\n",
      "        66.0       0.06      0.09      0.07      1916\n",
      "        67.0       0.05      0.05      0.05      1904\n",
      "        68.0       0.04      0.03      0.04      1927\n",
      "        69.0       0.06      0.01      0.02      1797\n",
      "        70.0       0.06      0.32      0.10      2516\n",
      "        71.0       0.06      0.09      0.07      2270\n",
      "        72.0       0.06      0.31      0.10      2593\n",
      "        73.0       0.06      0.02      0.02      1965\n",
      "        74.0       0.05      0.08      0.06      1950\n",
      "        75.0       0.06      0.02      0.03      1745\n",
      "        76.0       0.22      0.01      0.02      1454\n",
      "        77.0       0.00      0.00      0.00      1113\n",
      "        78.0       0.67      0.00      0.00      1180\n",
      "        79.0       0.14      0.02      0.03       883\n",
      "        80.0       0.00      0.00      0.00      1306\n",
      "        81.0       0.00      0.00      0.00      1084\n",
      "        82.0       0.00      0.00      0.00       872\n",
      "        83.0       0.00      0.00      0.00       655\n",
      "        84.0       0.00      0.00      0.00       563\n",
      "        85.0       0.00      0.00      0.00       440\n",
      "        86.0       0.00      0.00      0.00       362\n",
      "        87.0       0.00      0.00      0.00       220\n",
      "        88.0       0.00      0.00      0.00       195\n",
      "        89.0       0.00      0.00      0.00       117\n",
      "        90.0       0.00      0.00      0.00       322\n",
      "        91.0       0.00      0.00      0.00       235\n",
      "        92.0       0.00      0.00      0.00       137\n",
      "        93.0       0.00      0.00      0.00        81\n",
      "        94.0       0.00      0.00      0.00        39\n",
      "        95.0       0.00      0.00      0.00        12\n",
      "        96.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.06     55194\n",
      "   macro avg       0.05      0.02      0.02     55194\n",
      "weighted avg       0.08      0.06      0.04     55194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sharanbasavasumbad/python-env/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "decision_tree_classification_reprt = classification_report(y_test, y_pred)\n",
    "print(\"Decision Tree Classification report with selected data\")\n",
    "print(decision_tree_classification_reprt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2301a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
